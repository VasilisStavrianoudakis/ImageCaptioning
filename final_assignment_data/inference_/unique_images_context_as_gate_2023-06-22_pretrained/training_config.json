{
    "epochs": 50,
    "batch_size": 256,
    "lr": 0.0001,
    "weight_decay": 0,
    "patience": -1,
    "pretrained": true,
    "freeze": false,
    "decoder_params": {
        "embed_size": 300,
        "lstm_hidden_size": 2048,
        "num_layers": 1,
        "dropout_prob": 0.1,
        "vocab_size": 479
    },
    "encoder_params": {
        "dropout_prob": 0.0
    },
    "unfreeze_scheduler": null,
    "vocab_min_freq": 10,
    "start_token": "<START>",
    "bleu_n_gram": 2,
    "pretrained_embs_not_found_tokens": [
        "<START>",
        "<PAD>",
        "<UNK>"
    ]
}